{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bfcfb7fa3264f7f976f5cbeb7c2652c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aefb7295c7b42648615f79bcea1c9d6",
              "IPY_MODEL_47ed9578b3514240b4b40aeb510c4e08",
              "IPY_MODEL_f34f15034037487b8495f7a0e817d415"
            ],
            "layout": "IPY_MODEL_53f0ed8b2d7c4d20ad167a6ba7d274bf"
          }
        },
        "2aefb7295c7b42648615f79bcea1c9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9df8958f4604fc889fb31f8530bd21f",
            "placeholder": "​",
            "style": "IPY_MODEL_c2e5ede25329409eb28786a066b8960d",
            "value": " 18%"
          }
        },
        "47ed9578b3514240b4b40aeb510c4e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed7e14e6c654672b4ac4dea4241c2e5",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5c757b41ba8483aa859104419990930",
            "value": 4
          }
        },
        "f34f15034037487b8495f7a0e817d415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f399b49e6c074c06b65b4dd1b0f96de2",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e53a866a9e48948cb2129377474c4a",
            "value": " 3/17 [00:00&lt;00:03,  3.97ba/s]"
          }
        },
        "53f0ed8b2d7c4d20ad167a6ba7d274bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9df8958f4604fc889fb31f8530bd21f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e5ede25329409eb28786a066b8960d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed7e14e6c654672b4ac4dea4241c2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c757b41ba8483aa859104419990930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f399b49e6c074c06b65b4dd1b0f96de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e53a866a9e48948cb2129377474c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Albmargar1/ClickbaitDetector/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name = 'Index'> </a> <font color='orange'> Índice </font>\n",
        "\n",
        "* [Notas iniciales](#NotasIniciales)\n",
        "* Instalación del entorno\n",
        "* [Pipeline](#Pipeline)\n",
        "* Análisis descriptivo de los datos\n",
        "* Pruebas, con input:\n",
        "  * 'postText' (Texto del tweet)\n",
        "    * Búsqueda de hiperparámetros en BERT\n",
        "    * Búsqueda de hiperparámetros en RoBERTa\n",
        "    * Búsqueda de hiperparámetros en XLN\n",
        "  * 'postText' (Texto del tweet) + 'targetKeywords'\n",
        "    * Búsqueda de hiperparámetros en BERT\n",
        "    * Búsqueda de hiperparámetros en RoBERTa\n",
        "    * Búsqueda de hiperparámetros en XLN\n",
        "  * 'postText' (Texto del tweet) + 'targetParagraphs'\n",
        "    * Búsqueda de hiperparámetros en Longformer\n",
        "* Evaluación del dataset para cada input y checkpoint correspondiente. \n",
        "  * Comparación con estado del arte\n",
        "* Análisis de errores"
      ],
      "metadata": {
        "id": "eSg944T3w4pG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ct1BrNhXcTBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"NotasIniciales\"> </a> <font color='orange'> Notas iniciales </font>\n",
        "\n",
        "* Cambiar métricas, aparecen uans de GLUE\n",
        "\n",
        "<font color='lightgreen'> Comentarios </font>\n",
        "* # NO EJECUTAR TODAS LAS CELDAS A LA VEZ\n",
        "* Este es el **archivo principal** donde se recogen todas las pruebas. **Cada prueba** posee una **configuración de parámetros difentes**, y llaman a una **única función** que recoge el pipeline global, controlando mediante flags qué funciones deben ejecutarse. Dichas funciones se encuentran todas en la carpeta 'utils'\n",
        "* El índice contiene enlaces a cada sección para una navegación más cómoda. \n",
        "\n",
        "<font color='lightgreen'> Referencias </font>\n",
        "\n",
        "Quiero mencionar dos proyectos que hacen un trabajo muy parecido. Aunque obtengo ideas de ellos, considero que no hay plagio. Dichos trabajos servirán como referencia para comparar el modelo aquí desarrollado.\n",
        "* [Click-BERT: Clickbait Detector with Bidirectional Encoder Representations\n",
        "from Transformers](https://github.com/PeterQiu0516/Click-BERT)\n",
        "* [BERT, XLNet or RoBERTa: The Best Transfer Learning Model to Detect\n",
        "Clickbaits](https://www.researchgate.net/publication/356276903_BERT_XLNet_or_RoBERTa_The_Best_Transfer_Learning_Model_to_Detect_Clickbaits)\n"
      ],
      "metadata": {
        "id": "7gKW0rtFV8kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='orange'> Parámetros </font>\n",
        "Por comodidad, los parámetros a ajustar se encuentran en la parte superior del cuaderno."
      ],
      "metadata": {
        "id": "IPBWMv7suN12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_config = {}\n",
        "\n",
        "# Directories\n",
        "default_config['train_dir'] = '/content/ClickbaitDetector/data/webis_train.csv'\n",
        "default_config['test_dir'] = '/content/ClickbaitDetector/data/webis_test.csv'\n",
        "\n",
        "# Flags\n",
        "default_config['do_descriptive_analysis'] = False\n",
        "default_config['do_training'] = False\n",
        "default_config['do_hyperparameter_search'] = False\n",
        "default_config['do_evaluation_test'] = False\n",
        "\n",
        "# Descriptive analysis\n",
        "default_config['logger_transformers'] = 'error'\n",
        "\n",
        "# Dataset\n",
        "default_config['train_val_split'] = 0.15\n",
        "default_config['clip'] = [0.5,0.5]\n",
        "default_config['inputs'] = ['postText']\n",
        "\n",
        "# Training\n",
        "default_config['learning_rate'] = 1e-5\n",
        "default_config['batch_size'] = 8\n",
        "default_config['num_epochs'] = 2\n",
        "default_config['weight_decay'] = 1e-5\n",
        "\n",
        "# Hyperparameter search\n",
        "default_config['n_trials'] = 2\n",
        "\n",
        "default_config['hp'] = {'learning_rate': [1e-6, 9e-5], # Uniform sampling between min-max\n",
        "                        'weight_decay': [4e-5, 1e-2], # Uniform sampling between min-max\n",
        "                        'epochs': [1,1], # Pick one between min-max\n",
        "                        'batch_size_train': [8, 16, 32]} # Pick one\n",
        "\n",
        "# Checkpoint\n",
        "default_config['checkpoint'] = 'bert-base-uncased'\n",
        "default_config['model_name'] = default_config['checkpoint'] + '-clickbait'\n",
        "default_config['finetuned_model_dir'] = './ClickbaitDetector/model/' + default_config['model_name']"
      ],
      "metadata": {
        "id": "5yKljtWtuXMV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Volver al índice](#Index)\n",
        "\n",
        "# <font color='orange'> Setup </font>\n",
        "Clonar el proyecto, instalar e importar dependencias. Puede durar varios minutos."
      ],
      "metadata": {
        "id": "P0j9DIrZvRU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1GB2qnF50ZP",
        "outputId": "15319b74-0ad4-42c3-f886-89393b470315",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ClickbaitDetector' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Albmargar1/ClickbaitDetector -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c-4X21ai0-ZD",
        "outputId": "66445b96-58bb-4bd3-e2b7-058aff1c56b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 367, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_criteria_to_update(candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 202, in _get_criteria_to_update\n",
            "    for r in self._p.get_dependencies(candidate=candidate):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 175, in get_dependencies\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 175, in <listcomp>\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 419, in iter_dependencies\n",
            "    for r in self.dist.requires():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
            "    yield Requirement(line)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/requirements.py\", line 113, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1943, in parseString\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4849, in parseImpl\n",
            "    loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4052, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 1687, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 2893, in parseImpl\n",
            "    raise ParseException(instring, loc, self.errmsg, self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pyparsing.py\", line 304, in __init__\n",
            "    def __init__(self, pstr, loc=0, msg=None, elem=None):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 213, in _main\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1366, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.7/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1127, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 130, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 616, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 566, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 104, in print_exception\n",
            "    type(value), value, tb, limit=limit).format(chain=chain):\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 508, in __init__\n",
            "    capture_locals=capture_locals)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 363, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 285, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 449, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 418, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 376, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q folium==0.2.1 # Tengo que especificar la versión de folium o da error al instalar la librería de datasets de Hugging Face"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C2Cx0ntf0-5z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna -q"
      ],
      "metadata": {
        "id": "3QnrN45yPRjV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/ClickbaitDetector/')\n",
        "\n",
        "import optuna\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from datasets import load_metric\n",
        "import torch\n",
        "\n",
        "\n",
        "from utils import data_processing, descriptive_analysis, trainer_funcs\n",
        "from utils.Objective import Objective"
      ],
      "metadata": {
        "id": "q9jqAcUi3U9b",
        "cellView": "code"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Volver al índice](#Index)\n",
        "<a name='Pipeline'> </a>\n",
        "# <font color='orange'> Pipeline </font>"
      ],
      "metadata": {
        "id": "pT3YTftcrQ5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = default_config\n",
        "config['do_training'] = True\n",
        "config['do_hyperparameter_search'] = True\n",
        "config['do_evaluation_test'] = False\n",
        "\n",
        "p = config \n",
        "\n",
        "data_train = data_processing.process_file(p['train_dir'])\n",
        "\n",
        "if p['do_descriptive_analysis']:\n",
        "  descriptive_analysis.overall_info(data_train)\n",
        "  descriptive_analysis.study_std(data_train)\n",
        "  descriptive_analysis.probability_clickbait_per_words_clickbait(data_train)\n",
        "  descriptive_analysis.given_word_check_probability_clickbait(data_train)\n",
        "\n",
        "else:\n",
        "  tokenizer = AutoTokenizer.from_pretrained(p['checkpoint'])\n",
        "  data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "  if p['do_training']:\n",
        "    data_dic_train = data_processing.to_Dataset(data_train,\n",
        "                                                p['inputs'],\n",
        "                                                clip=p['clip'],\n",
        "                                                split=True, \n",
        "                                                train_val_split = p['train_val_split'])\n",
        "    \n",
        "    tokenized_dataset = data_processing.tokenize_dataset(data_dic_train, \n",
        "                                                        tokenizer)\n",
        "    \n",
        "    if p['do_hyperparameter_search']:\n",
        "      objective = Objective(p, tokenizer, data_collator, tokenized_dataset)\n",
        "      study = optuna.create_study(study_name=p['model_name'], direction='maximize') \n",
        "      study.optimize(objective, n_trials=p['n_trials'], callbacks=[objective.callback]) \n",
        "      objective.best_model.save_pretrained(p['finetuned_model_dir'])\n",
        "\n",
        "  if p['do_evaluation_test']:\n",
        "    data_test = data_processing.process_file(p['test_dir'])\n",
        "    data_dic_test = data_processing.to_Dataset(data_test, \n",
        "                                              p['inputs'],\n",
        "                                              split=False)\n",
        "    \n",
        "    tokenized_dataset = data_processing.tokenize_dataset(data_dic_test, \n",
        "                                                        tokenizer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0bfcfb7fa3264f7f976f5cbeb7c2652c",
            "2aefb7295c7b42648615f79bcea1c9d6",
            "47ed9578b3514240b4b40aeb510c4e08",
            "f34f15034037487b8495f7a0e817d415",
            "53f0ed8b2d7c4d20ad167a6ba7d274bf",
            "c9df8958f4604fc889fb31f8530bd21f",
            "c2e5ede25329409eb28786a066b8960d",
            "bed7e14e6c654672b4ac4dea4241c2e5",
            "d5c757b41ba8483aa859104419990930",
            "f399b49e6c074c06b65b4dd1b0f96de2",
            "d8e53a866a9e48948cb2129377474c4a"
          ]
        },
        "id": "lwhkgthKO_w9",
        "outputId": "25ca698c-62b6-408a-9591-a6bccfcf68d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bfcfb7fa3264f7f976f5cbeb7c2652c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(p):\n",
        "  data_train = data_processing.process_file(p['train_dir'])\n",
        "\n",
        "  if p['do_descriptive_analysis']:\n",
        "    descriptive_analysis.overall_info(data_train)\n",
        "    descriptive_analysis.study_std(data_train)\n",
        "    descriptive_analysis.probability_clickbait_per_tweet_count_words(data_train)\n",
        "    descriptive_analysis.given_word_check_probability_clickbait(data_train)\n",
        "\n",
        "  else:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(p['checkpoint'])\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    if p['do_training']:\n",
        "      data_dic_train = data_processing.to_Dataset(data_train,\n",
        "                                                  p['inputs'],\n",
        "                                                  clip=p['clip'],\n",
        "                                                  split=True, \n",
        "                                                  train_val_split = p['train_val_split'])\n",
        "      \n",
        "      tokenized_dataset = data_processing.tokenize_dataset(data_dic_train, \n",
        "                                                          tokenizer)\n",
        "      \n",
        "      if p['do_hyperparameter_search']:\n",
        "        objective = Objective(p, tokenizer, data_collator, tokenized_dataset)\n",
        "        study = optuna.create_study(study_name=p['model_name'], direction='maximize') \n",
        "        study.optimize(objective, n_trials=p['n_trials'], callbacks=[objective.callback]) \n",
        "        objective.best_model.save_pretrained(p['finetuned_model_dir'])\n",
        "\n",
        "    if p['do_evaluation_test']:\n",
        "      data_test = data_processing.process_file(p['test_dir'])\n",
        "      data_dic_test = data_processing.to_Dataset(data_test, \n",
        "                                                p['inputs'],\n",
        "                                                split=False)\n",
        "      tokenized_dataset = data_processing.tokenize_dataset(data_dic_test, \n",
        "                                                          tokenizer)\n"
      ],
      "metadata": {
        "id": "8a4OnOqirSiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Volver al índice](#Index)\n",
        "# <font color='orange'> Análisis descriptivo </font>\n",
        "Se realiza un análisis descriptivo básico, que incluye: \n",
        "\n",
        "*   Variabilidad de los anotadores\n",
        "*   Probabilidad de clickbait en función del número de palabras por tweet\n",
        "*   Probabilidad de que la palabra pertenezca a un clickbait\n"
      ],
      "metadata": {
        "id": "2M41qt0tZliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#descriptive_config = default_config\n",
        "#descriptive_config['do_descriptive_analysis'] = True\n",
        "\n",
        "#pipeline(p=descriptive_config)"
      ],
      "metadata": {
        "id": "2Ag_ldG7dWXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='lightgreen'> Variabilidad de los anotadores </font>\n",
        "\n",
        "Resulta interesante observar la variación de las puntuaciones del conjunto de anotadores para cada tweet. Esto puede representarse como un diagrama de cajas de la desviación típica de las puntuaciones.\n",
        "\n",
        "A la vista de los datos, los anotadores no tienen un consenso muy definido entre sus valoraciones, lo cual podría resultar en confusiones a la hora de entrenar la red neuronal. \n",
        "\n",
        "Dado que los mayores valores de desviación típica implica que la correspondiente media está relativamente centrada (uno de los dos casos de mayor desviación típica sería el conjunto de puntuaciones [1, 1, 1, 0, 0], con media = 0.6 y desviación típica ~0.49), resulta relativamente seguro eliminar aquellos datos cuya media de las puntuaciones se encuentre cercana a 0.5.\n",
        "\n",
        "Esto además nos permite descartar tweets con conjuntos de puntuaciones no polarizados, por ejemplo [0.66, 0.66, 0.66, 0.33, 0.33]. Aunque dicho tweet se considere clickbait, el conjunto de los anotadores no tiene certeza de ello, y puede provocar errores de clasificación durante el entrenamiento.\n",
        "\n",
        "La cantidad de datos a descartar se tomará como un hiperparámetro. Esto puede perjudicar en que hay un menor número de datos que entrenar, por lo que no resulta obvio que vaya a mejorar el modelo. Por lo tanto, la cantidad de datos a descartar se tomará como un hiperparámetro.\n",
        "\n",
        "*Nota: Esta idea proviene de este proyecto: [Click-BERT: Clickbait Detector with Bidirectional Encoder Representations\n",
        "from Transformers](https://github.com/PeterQiu0516/Click-BERT/blob/main/Final-Report/EECS498NLP_Project_Final_Report.pdf)*, donde aseguran que mejoran las predicciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "V13lMtm8wECC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='lightgreen'> Probabilidad de clickbait en función del número de palabras por tweet </font>\n",
        "\n",
        "A la vista de la gráfica, podemos observar que la mayoría de tweets con un número de palabras muy bajo suele ser clickbait, y dicha probabilidad tiende a reducirse generalizadamente conforme aumenta el número de palabras. "
      ],
      "metadata": {
        "id": "oyhlkPdmff7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='lightgreen'> Probabilidad de que la palabra aparezca en un clickbait </font>\n",
        "\n",
        "Estos resultados no resultan muy reveladores, pero dan pequeñas pistas de qué se puede considerar legítimo y qué puede considerarse clickbait.\n",
        "\n",
        "Por ejemplo, entre las palabras que más aparecen en los tweets que son clickbaits aparecen apelativos al lector 'you'/'your', preguntas 'what'/'why' y adjetivos demostrativos 'this'/'these'. \n",
        "\n",
        "En el caso de tweets legítimos, parece que tiende a poseer palabras menos ambiguas, tales como 'u.s.'/'police'/'trump'/'president'.\n",
        "\n",
        "Igualmente hay clasificaciones extrañas. Por ejemplo, 'says' se ha catalogado como una palabra que se usa mucho en tweets legítimos, cuando es una palabra que puede recordar a un clickbait."
      ],
      "metadata": {
        "id": "nf470WCoxD5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='orange'> Hugging Face dataset y tokenización </font>"
      ],
      "metadata": {
        "id": "z0X6DOuJnlLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ykO0Ojc985fi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}